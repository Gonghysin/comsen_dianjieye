
## 项目简介
已经初步实现了用数据集来训练一个模型，用来预测分子的电离能和亲和能
训练用的数据集是QM9数据集
输入的是一个smiles字符串（分支化学式），输出的这是预测的电离能or亲和能
我目前训练的这个模型，是用来预测亲和能的

## 项目结构
- dataset # 数据集
    - raw_dataset # 原始数据集
    - processed_dataset # 处理后的数据集
- train_result # 训练结果
    - iamges # 图像
    - models # 训练后保存的结果
process_dataset.py # 数据集预处理脚本
train_model.py # 训练模型脚本
test_qm9.py # 暂时没用，不用管

一些文件我还没放到正确的文件夹下，先凑合着用

## 训练模型
训练用的python脚本是：train_model.py
里面有个函数 train_model(dataframe)，就是用来训练模型的。

### 数据集预处理
dataframe是读取之后的数据集，数据集需要预处理。读取的字段x,y，x是smiles字符串，y是亲和能。
```Python
    df = pd.read_csv('dataset/processed_dataset/processed_qm9.csv', 
                     header=0,
                     dtype={'x': str, 'y': float})
```
可以用process_dataset.py来处理数据集，输入的csv文件是QM9数据集，输出的csv文件是处理后的数据集。

### 将smiles转换成graph
smiles要先转换成graph，然后才能训练。
graph是一个分子图结构,用来表示分子中原子和化学键的连接关系:

- 节点(Nodes): 表示分子中的原子,每个节点包含原子的特征(如原子序数)
- 边(Edges): 表示原子之间的化学键,边的特征包含键的类型(单键、双键等)

在 train_model.py 中,使用 smiles_to_graph() 函数将 SMILES 字符串转换为图结构:
这样就得到了一个可以输入到神经网络的图数据结构。图神经网络可以通过图卷积等操作来学习分子的结构特征,从而预测分子的性质。


### 训练算法
训练算法是用的图神经网络，图神经网络的输入是图数据结构，输出是预测的亲和能。

优化器：使用Adam优化器，学习率为0.0005，权重衰减为1e-4
学习率调度器：使用ReduceLROnPlateau，当验证损失停止改善时降低学习率
损失函数：使用均方误差(MSE)作为回归任务的损失函数
梯度裁剪：防止梯度爆炸
早停机制：当验证损失在连续20个周期没有改善时停止训练

### 模型架构
使用的是一个分子图神经网络模型，包含：
1. NNConv层：使用边特征进行消息传递
2. GATConv层：图注意力网络层，使用4个注意力头
3. 全局池化：使用全局平均池化聚合节点特征
4. 残差连接：在卷积层之间使用残差连接
5. Dropout层：使用0.2的丢弃率防止过拟合

### 检查点回复
训练过程中，使用检查点保存最佳模型，以便在训练结束后加载最佳模型进行最终评估。

### 保存模型
训练结束后，将模型文件保存为"best_model.pt"，以便在预测时加载使用。
之后需要用这个模型预测的时候，直接加载这个模型文件即可，不需要重新训练一遍。

## 接下来的任务
### 学长指导的详细解析
学长的指导内容如下，我逐条分析并给出实施建议：

1. **优化算法，嵌入层明确原子信息，R²达到0.8以上**
   - **含义**：嵌入层是图神经网络的初始层，将原子信息（如原子序数、电负性、价电子数）转换为向量。你需要确保嵌入层使用的原子特征是相关的，并优化模型以达到R²≥0.8。R²是模型预测与真实值相关性的指标，0.8表示解释了80%的方差，表现较好。
   - **实施建议**：
     - 检查当前嵌入层如何定义，可能需要调整原子特征集。例如，增加电负性、原子半径等特征。
     - 尝试不同嵌入维度（如从64增加到128），或使用预训练的原子嵌入（如来自量子化学计算）。
     - 优化网络结构：增加GATConv层的层数，调整注意力头的数量，或尝试全局最大池化代替平均池化。
     - 超参数调优：调整学习率（例如0.001或0.0001），增大批次大小，或改变权重衰减。
     - 使用交叉验证确保模型泛化能力，报告测试集R²。

2. **用QM9数据集跑模型看效果**
   - **含义**：学长可能想确保模型在QM9数据集上的表现，尤其是测试集的泛化能力。由于你已用QM9训练，可能需要确认数据分割是否合理，或检查是否有过拟合。
   - **实施建议**：
     - 确保数据集正确分割：训练集（70%）、验证集（15%）、测试集（15%），或类似比例。
     - 运行模型，报告训练集、验证集和测试集的R²，检查是否有过拟合（训练R²高，测试R²低）。
     - 如果测试R²未达0.8，回溯到第一步优化模型。

3. **研究CVAE，既预测又生成满足LUMO-HOMO的分子SMILES**
   - **含义**：CVAE是条件变分自编码器，能生成数据，同时受条件控制。这里条件是LUMO-HOMO值（最低未占分子轨道和最高占分子轨道的能量差，影响分子光学和电子性质）。目标是给定LUMO-HOMO范围，生成可能的分子SMILES。
   - **实施建议**：
     - 学习CVAE原理，参考相关论文如[Conditional Variational Autoencoders for Molecular Generation](https://arxiv.org/abs/1703.10650)。
     - 实现步骤：
       1. 编码SMILES到潜在空间，使用图神经网络或RNN编码。
       2. 解码生成SMILES，条件是LUMO-HOMO值，需训练模型学习这种映射。
       3. 使用QM9数据集，LUMO-HOMO值可能已在数据集内，需提取。
     - 这任务较复杂，可能需要额外计算资源，建议优先完成前两项后视时间安排。

4. **使用SHAP可解释性分析，丰富PPT内容**
   - **含义**：SHAP（SHapley Additive exPlanations）是解释机器学习模型预测的方法，能显示每个特征对预测的贡献。在图神经网络中，特征包括节点（原子）和边（化学键）的属性。分析后可理解哪些部分影响亲和能预测，适合比赛PPT展示。
   - **实施建议**：
     - 使用Python的SHAP库，需定义模型预测函数，输入是分子图，输出是亲和能预测。
     - 对每个节点和边的特征计算SHAP值，解释哪个原子或键对预测最重要。
     - 参考[SHAP Documentation](https://shap.readthedocs.io/en/latest/)，或搜索图神经网络的SHAP应用论文。
     - 将结果可视化，例如热图显示重要原子，添加到PPT中。

#### 实施优先级与时间管理
建议按以下顺序推进：
1. **评估当前模型**：运行`train_model.py`，报告测试R²，确认是否≥0.8。
2. **若未达标，优化模型**：重点调整嵌入层和网络结构，调优超参数。
3. **完成SHAP分析**：用SHAP解释预测，准备PPT内容。
4. **若时间充足，研究CVAE**：探索分子生成，视进度决定深度。

#### 潜在挑战与注意事项
- **嵌入层优化**：确保原子特征全面，可能需要化学知识补充（如电负性影响亲和能）。
- **CVAE实现**：计算资源需求高，建议先参考现有实现，如[Molecular Generation with Variational Autoencoders](https://github.com/aspuru-guzik-group/chemical_vae)。
- **SHAP应用**：图数据解释较复杂，可能需要额外学习图神经网络的可解释性方法。


